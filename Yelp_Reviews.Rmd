---
title: "yelp_reviews"
author: "Swagata Chakraborty"
date: "6/21/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Load Libraries:
```{r}
library(ggmap)
library(ggplot2)
library(dplyr)
library(tidyverse)
library(scales)
library(lubridate)
```

# Load Dataset:
```{r}
load('data/vegas_hotels.rda')
```

This data contains customer reviews of 18 hotels in Las Vegas. We can use the ggmap library to plot the hotel locations:
```{r}
ggmap(get_map("The Strip, Las Vegas, Nevada",zoom=15,color = "bw")) +   
    geom_text(data=business,
              aes(x=longitude,y=latitude,label=name),
              size=3,color='red') 
```

# Rating Plot:

## The below plot shows the average rating for each of the hotels and the size of the points shows how many review datapoints we have (n)
```{r}
reviews %>%
  left_join(select(business,business_id,name),
             by='business_id') %>%
  group_by(name) %>%
  summarize(n = n(),
            mean.star = mean(as.numeric(stars))) %>%
  arrange(desc(mean.star)) %>%
  ggplot() + 
  geom_point(aes(x=reorder(name,mean.star),y=mean.star,size=n))+
  coord_flip() +
  ylab('Mean Star Rating (1-5)') + 
  xlab('Hotel')
```
\  

So The Venetian, Bellagio and The Cosmopolitan are clearly the highest rated hotels, while Luxor and LVH are the lowest rated. Ok, but what is behind these ratings? What are customers actually saying about these hotels? This is what we can hope to find through a text analysis.


# Document Term Matrix (DTM): 

Document Term Matrix: This is an array where each row corresponds to a document and each column corresponds to a word. The entries of the array are simply counts of how many times a certain word occurs in a certain document. 

Load required libraries
```{r}
## install packages
#install.packages(c("tm","wordcloud","tidytext"))  ## only run once
library(tm)
library(tidytext)
library(wordcloud)
```

## DTM : stopwords (remove insignificant word), stemming (root word handling), wordLength adjustment for considering Bag Of words
Let us summarize the reviews for the Aria hotel:
```{r}
## get id of hotel aria from business table
aria.id <- filter(business,name=='Aria Hotel & Casino')$business_id


## using aria id, find the corresponding review in review table
aria.reviews <- filter(reviews, business_id==aria.id) %>%
                rename(doc_id=review_id)
```


construct DTM:
```{r}
## code adjustment
aria.reviews[,sapply(aria.reviews,is.character)] <- sapply(
    aria.reviews[,sapply(aria.reviews,is.character)],
    iconv,"WINDOWS-1252","UTF-8")


## convert dataframe to class corpus 
## text part of each doc
text.c <- VCorpus(DataframeSource(select(aria.reviews,doc_id,text)))

## other info part of each doc
meta.data <- aria.reviews %>%
             select(doc_id,stars,votes.funny,votes.useful,votes.cool,date) %>%
             rename(document=doc_id)


## DTM of the  text part of each Doc
DTM.aria <- DocumentTermMatrix(text.c,
                          control=list(removePunctuation=TRUE,
                                       wordLengths=c(3, Inf),
                                       stopwords=TRUE,
                                       stemming=TRUE,
                                       removeNumbers=TRUE
                                       ))

## inspection shows that we have lotf buffer jibber words like aaaaa....owwww...etc, which needs handling
inspect(DTM.aria[1:10, 1:10])
```

sparsity handling for jibber words: There are a total of 10,197 terms as shown by below print command. That’s a lot and many of them are meaningless and sparse, i.e., they only occur in a few documents. The following command will remove terms that doesn’t occur in 99.5% of documents
```{r}
print(DTM.aria) ## 10197 unique terms including jibber words

DTM.aria.sp <- removeSparseTerms(DTM.aria,0.995)
inspect(DTM.aria.sp[1:10, 1:10])
print(DTM.aria.sp) ## 1787 unique terms including jibber words
```
?? difference between entries 140750 and terms 1787


## Summarizing a Document Term Matrix:
What are the top frequent words:
```{r}
library(forcats)

aria.tidy <- tidy(DTM.aria.sp)

term.count <- aria.tidy %>%
              group_by(term) %>%
              summarize(n.total=sum(count)) %>%
              arrange(desc(n.total))

## top 30 words
term.count %>% 
  slice(1:30) %>%
  ggplot(aes(x=fct_reorder(term,n.total),y=n.total)) + geom_bar(stat='identity') + 
  coord_flip() + xlab('Counts') + ylab('')+ggtitle('Most Frequent Terms')
```
It seems that in case of Aria hotels people tend to talk a lot about room, hotel and stay and less about strip, pool and light.


## word cloud visualization:
```{r}
#top 95 words
term.count.pop <- term.count %>% slice(5:100) 
wordcloud(term.count.pop$term, term.count.pop$n.total, scale=c(5,.5))
```

## right now we just know how frequently are words being used, which are the common ones, but still we do not know what is the sentiment behind it.

# Word Association Plots:
```{r}
# words associated with room and bathroom
room <- data.frame(findAssocs(DTM.aria.sp, "room", 0.35)) # find terms correlated with "room" with cut-off 0.35 
bathroom <- data.frame(findAssocs(DTM.aria.sp, "bathroom", 0.2))

# plots
 p1 <- room %>%
  rownames_to_column() %>%
  ggplot(aes(x=reorder(rowname,room),y=room)) + geom_point(size=4) + 
  coord_flip() + ylab('Correlation') + xlab('Term') + 
  ggtitle('Terms correlated with Room')


p2 <-bathroom %>%
  rownames_to_column() %>%
  ggplot(aes(x=reorder(rowname,bathroom),y=bathroom)) + geom_point(size=4) + 
  coord_flip() + ylab('Correlation') + xlab('Term') + 
  ggtitle('Terms correlated with Bathroom')

gridExtra::grid.arrange(p1, p2, ncol=2)
```

Excercise:

Categorical Analysis: look into this consider separate analyses for satisfied and non-satisfied visitors (with satisfied visitors defined as having 5 star rated reviews and non-satisfied visitors having 1 or 2 star reviews)
```{r}
aria.tidy.meta <- aria.tidy %>%
  inner_join(meta.data,by="document")  ## this now has star ratings too

dtm <- aria.tidy %>% 
  cast_dtm(document, term, count) 


## categorized DTM

###  satisfied
dtm_satisfied <- aria.tidy.meta %>% filter(stars==5) %>% cast_dtm(document, term, count)  

###  unsatisfied
dtm_unsatisfied <- aria.tidy.meta %>% filter(stars %in% c(1,2)) %>% cast_dtm(document, term, count)  
```

Analysis for satisfied:
```{r}
aria.tidy.sat <- tidy(dtm_satisfied)
aria.tidy.unsat <- tidy(dtm_unsatisfied)

term.count.sat <- aria.tidy.sat %>%
              group_by(term) %>%
              summarize(n.total=sum(count)) %>%
              arrange(desc(n.total))

term.count.unsat <- aria.tidy.unsat %>%
              group_by(term) %>%
              summarize(n.total=sum(count)) %>%
              arrange(desc(n.total))

## top 30 words
p1 <-term.count.sat %>% 
  slice(1:30) %>%
  ggplot(aes(x=fct_reorder(term,n.total),y=n.total)) + geom_bar(stat='identity') + 
  coord_flip() + xlab('Counts') + ylab('')+ggtitle('Most Frequent Terms amongst satisfied')

p2 <-term.count.unsat %>% 
  slice(1:30) %>%
  ggplot(aes(x=fct_reorder(term,n.total),y=n.total)) + geom_bar(stat='identity') + 
  coord_flip() + xlab('Counts') + ylab('')+ggtitle('Most Frequent Terms amongst dissatisfied')

gridExtra::grid.arrange(p1, p2, ncol=2)
```
room hotel and stay are still the most common words, however in the lower common ones are pool, amaz, back

```{r}
term.count.pop.sat <- term.count.sat %>%
  slice(5:100) 

term.count.pop.unsat <- term.count.unsat %>%
  slice(5:100) 
  
p1<-wordcloud(term.count.pop.sat$term, term.count.pop.sat$n.total, scale=c(5,.5))
p2<-wordcloud(term.count.pop.unsat$term, term.count.pop.unsat$n.total, scale=c(5,.5))

gridExtra::grid.arrange(p1, p2, ncol=2)
```

Association:
```{r}
## room
room.sat <- data.frame(findAssocs(dtm_satisfied, "room", 0.35)) # find terms correlated with "room" 
room.unsat <- data.frame(findAssocs(dtm_unsatisfied, "room", 0.35)) # find terms correlated with "room" 

room.sat %>%
  rownames_to_column() %>%
  ggplot(aes(x=reorder(rowname,room),y=room)) + geom_point(size=4) + 
  coord_flip() + ylab('Correlation') + xlab('Term') + 
  ggtitle('Terms correlated with Room for satisfied')

room.unsat %>%
  rownames_to_column() %>%
  ggplot(aes(x=reorder(rowname,room),y=room)) + geom_point(size=4) + 
  coord_flip() + ylab('Correlation') + xlab('Term') + 
  ggtitle('Terms correlated with Room for dissatisfied')
```

## Time Analysis: how do word frequencies change over time? In the following we focus on the terms “buffet”,“pool” and “staff”.
```{r}
  total.terms.time <- aria.tidy.meta %>%
  group_by(date) %>%
  summarize(n.total=sum(count))

## for the legend 
a <- 1:nrow(total.terms.time)
b <- a[seq(1, length(a), 3)]

aria.tidy.meta %>%
  filter(term %in% c("pool","staff","buffet")) %>%
  group_by(term,date) %>%
  summarize(n = sum(count)) %>%
  left_join(total.terms.time, by='date') %>%
  ggplot(aes(x=date,y=n/n.total,color=term,group=term)) + 
  geom_line() + 
  facet_grid(term~.)+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))+
  scale_x_discrete(breaks=as.character(total.terms.time$date[b]))+
  scale_y_continuous(labels=percent)+xlab('Year/Month')+
  ylab('Word Frequency relative to Month Total')+ggtitle('Dynamics of Word Frequency for Aria Hotel')
```
 Now let us do the same but aggregated by year separately for the two segments.
```{r}
aria.tidy2 <- aria.tidy.meta %>%
  mutate(year = year(date),
         satisfaction = fct_recode(factor(stars),
                                   "Not Satisfied"="1",
                                   "Not Satisfied"="2",
                                   "Neutral"="3",
                                   "Neutral"="4",
                                   "Satisfied"="5"))


total.terms.rating.year <- aria.tidy2 %>%
  group_by(satisfaction,year) %>%
  summarize(n.total = sum(count)) 


aria.tidy2 %>%
  filter(term %in% c("pool","staff","buffet","food","wait","casino","line","check","clean")) %>%
  group_by(satisfaction,year,term) %>%
  summarize(n = sum(count)) %>%
  left_join(total.terms.rating.year, by=c('year','satisfaction')) %>%
  ggplot(aes(x=year,y=n/n.total,color=satisfaction,group=satisfaction)) + 
  geom_line(size=1,alpha=0.25) + geom_point() + 
  facet_wrap(~term,scales='free')+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))+
  scale_y_continuous(labels=percent)+xlab('Year')+
  ylab('Word Frequency relative to Month Total')+
  labs(title='Dynamics of Word Frequency for Aria Hotel',
       subtitle='Three Satisfaction Segments')
```

# Competitive Analysis:
Compare the relative word frequency within a resort across different resorts:
```{r}
reviews_all <-reviews %>%
              left_join(select(business,business_id,name),by='business_id')

reviews_all %>%
  count(name,sort=T)
```


```{r}
reviews_all <- reviews_all %>%
  mutate(doc_id = review_id)

meta.data <- reviews_all %>%
  select(name,doc_id,stars) %>%
  rename(document = doc_id)
```


```{r}

reviews_all[,sapply(reviews_all,is.character)] <- sapply(
    reviews_all[,sapply(reviews_all,is.character)],
    iconv,"WINDOWS-1252","UTF-8")

# create new Doc Matrix:
text.all <- VCorpus(DataframeSource(select(reviews_all,doc_id,text)))
DTM.all <- DocumentTermMatrix(text.all,
                              control=list(removePunctuation=TRUE,
                                           wordLengths=c(3, Inf),
                                           stopwords=TRUE,
                                           stemming=TRUE,
                                           removeNumbers=TRUE
                              ))
```

```{r}
all.tidy <- tidy(removeSparseTerms(DTM.all,0.995))

total.term.count.hotel <- all.tidy %>%
  inner_join(meta.data,by='document') %>%
  group_by(name) %>%
  summarize(n.total=sum(count))

term.count.hotel.rel <- all.tidy %>%
  inner_join(meta.data,by='document') %>%
  group_by(name,term) %>%
  summarize(n=sum(count)) %>%
  inner_join(total.term.count.hotel,by='name') %>%
  mutate(n.rel=n/n.total) 


plot_func <-function(word) {
  p <-term.count.hotel.rel %>%
  filter(term %in% c(word)) %>%
  ggplot(aes(x=name,y=n.rel,fill=name)) + geom_bar(stat='identity') + 
  facet_wrap(~term,ncol=1,scales='free_y') +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  theme(legend.position="none")
  return(p)
}


term_vector  <- c("buffet","pool","casino","bathroom","price","shower","bad","charg","upgrad","decor")

for (text in term_vector){
 print(plot_func(text) )
}

```

